{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.models as M\n",
    "import tensorflow.keras.optimizers as O\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Class for data loader. It takes the training or evaluation data and creates an object of Sequence class \n",
    "from Keras. The class takes care of loading batch of images while training the model and discarding them after use.\n",
    "This class is used to create objects for model with sift features.\n",
    "'''\n",
    "class CNN_Loader(Sequence):\n",
    "    def __init__(self, img_paths, targets, batch_size):\n",
    "        self.img_paths, self.targets = img_paths, targets\n",
    "        self.batch_size = batch_size\n",
    "        #self.all_y = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.img_paths) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_imgs = self.img_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.targets[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        images = []\n",
    "        s_features = []\n",
    "        for filename in batch_imgs:\n",
    "            img = cv2.imread(\"data/\"+filename, cv2.IMREAD_COLOR)\n",
    "            images.append(np.transpose(image.img_to_array(image.load_img(\"data/\"+filename, target_size=(224, 224))),(1,0,2)))\n",
    "            blur = cv2.blur(img,(50,50))\n",
    "            d_temp = np.zeros((25600,))\n",
    "            blur2 = cv2.GaussianBlur(img,(3,3),0)\n",
    "            absd=cv2.equalizeHist(cv2.cvtColor(cv2.absdiff(blur2,blur),cv2.COLOR_BGR2GRAY))\n",
    "            saliency = cv2.saliency.StaticSaliencyFineGrained_create()\n",
    "            (success, saliencyMap) = saliency.computeSaliency(absd)\n",
    "            threshMap = cv2.threshold(saliencyMap.astype(\"uint8\"), 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "            ss = saliencyMap.copy()\n",
    "            ss[:40, :] = 0\n",
    "            ss[:, :20] = 0\n",
    "            ss[:, -20:] = 0\n",
    "            sift1 = cv2.xfeatures2d.SIFT_create(200)\n",
    "            kp1, desc = sift1.detectAndCompute(ss, None)\n",
    "            f = desc.flatten()\n",
    "            if desc is not None:\n",
    "                d_temp[:min(25600,len(f))] = f[:25600]\n",
    "            s_features.append(d_temp)\n",
    "        s_features = np.asarray(s_features)\n",
    "        return [np.array(images), s_features], np.array(batch_y)\n",
    "   \n",
    "''' Class for data loader. It takes the training or evaluation data and creates an object of Sequence class \n",
    "from Keras. The class takes care of loading batch of images while training the model and discarding them after use.\n",
    "This class is used to create objects for model without sift features.\n",
    "'''\n",
    "\n",
    "class CNN_Loader_with_sift(Sequence):\n",
    "    def __init__(self, img_paths, targets, batch_size):\n",
    "        self.img_paths, self.targets = img_paths, targets\n",
    "        self.batch_size = batch_size\n",
    "        #self.all_y = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.img_paths) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_imgs = self.img_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.targets[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        images = []\n",
    "        for filename in batch_imgs:\n",
    "            images.append(np.transpose(image.img_to_array(image.load_img(\"data/\"+filename, target_size=(224, 224))),(1,0,2)))\n",
    "        return np.array(images), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function loads the given model'''\n",
    "def load_model(name):\n",
    "    json_file = open('./Models/'+name+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(\"./Models/\"+name+\".h5\")\n",
    "    return loaded_model\n",
    "\n",
    "'''This function creates the image data loader object'''\n",
    "def get_data_gen(csv_path, sift):\n",
    "    data = pd.read_csv(csv_path, header=None)\n",
    "    data=data.sample(frac=1)\n",
    "    x_train, y_train = data.iloc[:,0].values, data.iloc[:,1].astype(int).values\n",
    "    return CNN_Loader(x_train, y_train, 32) if sift else CNN_Loader_with_sift(x_train, y_train, 32)\n",
    "\n",
    "'''This function returns the scores calculated between the predictions and truth values'''\n",
    "def scoring(pred, all_y):\n",
    "    accuracy = accuracy_score(all_y, pred)\n",
    "    precision = precision_score(all_y, pred)\n",
    "    recall = recall_score(all_y, pred)\n",
    "    return {'accuracy': accuracy, 'precision':precision, 'recall':recall}\n",
    "\n",
    "'''This function writes the label on the images and saves them in a new directory for creating a video'''\n",
    "def write_images(img_paths,pred, dest_path, task_name):\n",
    "    for i in range(len(img_paths)):\n",
    "        im = cv2.imread(\"data/\"+img_paths[i])\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text = \"False\" if np.round(pred[i])==0 else \"True\"\n",
    "        cv2.putText(im, text, (20,160), font, 3, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.imwrite(dest_path+\"/\"+img_paths[i].split(\"/\")[-1], im)\n",
    "\n",
    "'''This function creates a video using the images stored with labels using the write_images function'''\n",
    "def create_video(path_to_dir, img_paths):\n",
    "    img_array = []\n",
    "    files = os.listdir(path_to_dir)\n",
    "    files = [i for i in files if \"jpg\" in i] \n",
    "    size = (0, 0)\n",
    "    for filename in files:\n",
    "        img = cv2.imread(path_to_dir+\"/\"+filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        img_array.append(img)\n",
    " \n",
    "    out = cv2.VideoWriter(path_to_dir+\"/\"+'project.avi',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "    out.release()\n",
    "\n",
    "'''The master function that takes the task name and whether or not we use sift features and gets the inference \n",
    "scores'''\n",
    "def inference_model(task_name, sift):\n",
    "    csv_path = \"./data/\"+task_name+\"_test_data.csv\"\n",
    "    if sift == True:\n",
    "        model_name = \"CNN_model_xception_sift_full_\"+task_name\n",
    "        dest_path = \"data/Final_Predictions/\"+task_name+\"_with_sift\"\n",
    "    else:\n",
    "        model_name = \"CNN_model_xception_full_\"+task_name\n",
    "        dest_path = \"data/Final_Predictions/\"+task_name\n",
    "    model = load_model(model_name)\n",
    "    print('Model loaded...')\n",
    "    eval_data_gen = get_data_gen(csv_path, sift)\n",
    "    pred = model.predict_generator(eval_data_gen)\n",
    "    print('Got predictions...')\n",
    "    scores = scoring(np.round(pred), eval_data_gen.targets)\n",
    "    print(scores)\n",
    "    print(confusion_matrix(np.round(pred),eval_data_gen.targets))\n",
    "#     try:\n",
    "#         os.mkdir(dest_path)\n",
    "#     except:\n",
    "#         pass\n",
    "#     write_images(eval_data_gen.img_paths, pred, dest_path, task_name)\n",
    "#     create_video(dest_path, eval_data_gen.img_paths)\n",
    "#     print('Video created...')\n",
    "#     play_video(dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded...\n",
      "Got predictions...\n",
      "{'accuracy': 0.9087603305785124, 'precision': 0.4444444444444444, 'recall': 0.010899182561307902}\n",
      "[[10984  1089]\n",
      " [   15    12]]\n"
     ]
    }
   ],
   "source": [
    "inference_model(\"jumpshot\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded...\n",
      "Got predictions...\n",
      "{'accuracy': 0.909741144414169, 'precision': 1.0, 'recall': 0.00749063670411985}\n",
      "[[2669  265]\n",
      " [   0    2]]\n"
     ]
    }
   ],
   "source": [
    "inference_model(\"jumpball\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded...\n",
      "Got predictions...\n",
      "{'accuracy': 0.9095041322314049, 'precision': 0.5046153846153846, 'recall': 0.29791099000908267}\n",
      "[[10677   773]\n",
      " [  322   328]]\n"
     ]
    }
   ],
   "source": [
    "inference_model(\"jumpshot\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded...\n",
      "Got predictions...\n",
      "{'accuracy': 0.9086776859504132, 'precision': 0.49606299212598426, 'recall': 0.22888283378746593}\n",
      "[[10743   849]\n",
      " [  256   252]]\n"
     ]
    }
   ],
   "source": [
    "inference_model(\"jumpshot\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded...\n",
      "Got predictions...\n",
      "{'accuracy': 0.9037389970120326, 'precision': 0.44365572315882873, 'recall': 0.22153300841825432}\n",
      "[[21882  1757]\n",
      " [  627   500]]\n"
     ]
    }
   ],
   "source": [
    "inference_model(\"three_point\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CODE\n",
    "model = load_model(\"CNN_model_xception_full_jumpball\")\n",
    "# model = load_model(\"CNN_model_xception_sift_full_jumpball\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CODE\n",
    "img = cv2.imread(im_name, cv2.IMREAD_COLOR)\n",
    "img1 = np.expand_dims(np.transpose(image.img_to_array(image.load_img(im_name, target_size=(224, 224))),(1,0,2)),axis=0)\n",
    "blur = cv2.blur(img,(50,50))\n",
    "d_temp = np.zeros((25600,))\n",
    "blur2 = cv2.GaussianBlur(img,(3,3),0)\n",
    "absd=cv2.equalizeHist(cv2.cvtColor(cv2.absdiff(blur2,blur),cv2.COLOR_BGR2GRAY))\n",
    "saliency = cv2.saliency.StaticSaliencyFineGrained_create()\n",
    "(success, saliencyMap) = saliency.computeSaliency(absd)\n",
    "threshMap = cv2.threshold(saliencyMap.astype(\"uint8\"), 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "ss = saliencyMap.copy()\n",
    "ss[:40, :] = 0\n",
    "ss[:, :20] = 0\n",
    "ss[:, -20:] = 0\n",
    "sift1 = cv2.xfeatures2d.SIFT_create(200)\n",
    "kp1, desc = sift1.detectAndCompute(ss, None)\n",
    "f = desc.flatten()\n",
    "if desc is not None:\n",
    "    d_temp[:min(25600,len(f))] = f[:25600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CODE\n",
    "# model.predict([img1,d_temp.reshape(1,-1)])\n",
    "# model.predict(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
